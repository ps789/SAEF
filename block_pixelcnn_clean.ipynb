{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULakBh5bqY8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04acbf0f-6599-4c45-b950-4afcc9c1fd4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, LeakyReLU, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdhPTbRcrbx",
        "outputId": "c896c8ea-8899-435b-d831-8855b0ffc8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/pixelcnn\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/pixelcnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcI9AMFXqY8T"
      },
      "source": [
        "## Prepare dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "n_dims = 28\n",
        "n_residual_blocks = 10\n",
        "batch_size = 1500\n",
        "n_epoch = 30\n",
        "\n",
        "n_block_x_dim = 4\n",
        "n_block_y_dim = 4\n",
        "\n",
        "\n",
        "n_block_dim = n_block_x_dim * n_block_y_dim\n",
        "n_hidden = 10\n",
        "z_dim = n_block_dim\n",
        "\n",
        "n_residual_blocks = 3\n",
        "batch_size = 200\n",
        "n_epoch = 2000"
      ],
      "metadata": {
        "id": "RnVGYwgaX8VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v02grysEqY8T"
      },
      "outputs": [],
      "source": [
        "# The data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(labels, n_x_blocks, n_y_blocks, n=10):\n",
        "  one_hot = np.zeros((len(labels), n_x_blocks, n_y_blocks, n))\n",
        "  for i in range(1, len(labels)):\n",
        "    one_hot[i, :, :, labels[i]] = 1.\n",
        "  return one_hot.astype(np.float32)"
      ],
      "metadata": {
        "id": "bj6aT32-bY_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxzl4y2bymOi"
      },
      "outputs": [],
      "source": [
        "# data preprocessing parameters\n",
        "n_x_dim = n_dims\n",
        "n_y_dim = n_dims\n",
        "\n",
        "n_blocks = int((n_x_dim * n_y_dim) / (n_block_x_dim * n_block_y_dim))\n",
        "n_x_blocks = int(n_x_dim / n_block_x_dim)\n",
        "n_y_blocks = int(n_y_dim / n_block_y_dim)\n",
        "\n",
        "input_shape = (n_x_blocks, n_y_blocks, n_block_x_dim * n_block_y_dim)\n",
        "\n",
        "y_train = to_one_hot(y_train, n_x_blocks, n_y_blocks, 10)\n",
        "y_test = to_one_hot(y_test, n_x_blocks, n_y_blocks, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_x_data_rnn(data_x, n_dims, n_x_blocks, n_y_blocks, n_block_dim):\n",
        "  data_x = data_x.reshape((data_x.shape[0], n_dims, n_dims))\n",
        "  x_rnn = np.zeros((data_x.shape[0], n_x_blocks, n_y_blocks, n_block_dim),\n",
        "                   dtype=np.float32)\n",
        "  for i in range(data_x.shape[0]):\n",
        "      for xi in range(n_x_blocks):\n",
        "          for yi in range(n_y_blocks):\n",
        "              x_start = xi * n_block_x_dim\n",
        "              x_end = (xi + 1) * n_block_x_dim\n",
        "              y_start = yi * n_block_y_dim\n",
        "              y_end = (yi + 1) * n_block_y_dim\n",
        "              x_rnn[i, xi, yi, :] = data_x[\n",
        "                  i, x_start: x_end, y_start: y_end].flatten()\n",
        "  return x_rnn"
      ],
      "metadata": {
        "id": "8oHWSQubdX03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vajqM2nmyvFB"
      },
      "outputs": [],
      "source": [
        "# prep dataset\n",
        "x_train_rnn = create_x_data_rnn(\n",
        "    x_train, n_dims, n_x_blocks, n_y_blocks, n_block_dim)\n",
        "x_test_rnn = create_x_data_rnn(\n",
        "    x_test, n_dims, n_x_blocks, n_y_blocks, n_block_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = x_train_rnn.shape[-1]\n",
        "z_dim = x_train_rnn.shape[-1]"
      ],
      "metadata": {
        "id": "DpLSnaW1itjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNES58snH1JF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c27b597c-06f9-4674-82c4-4978b2f7dea8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = np.zeros((n_x_dim, n_x_dim))\n",
        "for i in range(n_x_blocks):\n",
        "    for j in range(n_y_blocks):\n",
        "        digit = x_train_rnn[1001,i, j,:].reshape([n_block_x_dim, n_block_y_dim])\n",
        "        figure[i * n_block_x_dim: (i + 1) * n_block_x_dim,\n",
        "               j * n_block_y_dim: (j + 1) * n_block_y_dim] = digit\n",
        "\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDdNcUxGqY8U"
      },
      "source": [
        "## Base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKF0jsy6qY8U"
      },
      "outputs": [],
      "source": [
        "# The first layer is the PixelCNN layer. This layer simply\n",
        "# builds on the 2D convolutional layer, but includes masking.\n",
        "class PixelConvLayer(layers.Layer):\n",
        "    def __init__(self, mask_type, **kwargs):\n",
        "        super(PixelConvLayer, self).__init__()\n",
        "        self.mask_type = mask_type\n",
        "        self.conv = layers.Conv2D(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the conv2d layer to initialize kernel variables\n",
        "        self.conv.build(input_shape)\n",
        "        # Use the initialized kernel to create the mask\n",
        "        kernel_shape = self.conv.kernel.get_shape()\n",
        "        self.mask = np.zeros(shape=kernel_shape)\n",
        "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
        "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
        "        if self.mask_type == \"B\":\n",
        "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
        "        return self.conv(inputs)\n",
        "\n",
        "\n",
        "# Next, we build our residual block layer.\n",
        "# This is just a normal residual block, but based on the PixelConvLayer.\n",
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(ResidualBlock, self).__init__(**kwargs)\n",
        "        self.conv1 = keras.layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"linear\"\n",
        "        )\n",
        "        self.pixel_conv = PixelConvLayer(\n",
        "            mask_type=\"B\",\n",
        "            filters=filters,\n",
        "            kernel_size=3,\n",
        "            activation=\"linear\",\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.activation = layers.LeakyReLU(0.1)\n",
        "        self.conv2 = keras.layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"linear\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.activation(x)\n",
        "        x = self.pixel_conv(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        return keras.layers.add([inputs, x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3Nf5ps5eMfB"
      },
      "outputs": [],
      "source": [
        "def makeScaleMatrix(num_gen, num_orig):\n",
        "        # first 'N' entries have '1/N', next 'M' entries have '-1/M'\n",
        "        s1 =  tf.constant(1.0 / num_gen, shape = [num_gen, 1])\n",
        "        s2 = - tf.constant(1.0 / num_orig, shape = [num_orig, 1])\n",
        "        return tf.concat([s1, s2], axis=0)\n",
        "\n",
        "\n",
        "def _mmd_loss1(x, gen_x, sigma = [2, 5, 10, 20, 40, 80]):\n",
        "        # concatenation of the generated images and images from the dataset\n",
        "        # first 'N' rows are the generated ones, next 'M' are from the data\n",
        "        X = tf.concat([gen_x, x], axis=0)\n",
        "\n",
        "        # dot product between all combinations of rows in 'X'\n",
        "        XX = tf.matmul(X, tf.transpose(X))\n",
        "\n",
        "        # dot product of rows with themselves\n",
        "        X2 = tf.reduce_sum(X * X, 1, keepdims=True)\n",
        "\n",
        "        # exponent entries of the RBF kernel (without the sigma) for each\n",
        "        # combination of the rows in 'X'\n",
        "        # -0.5 * (x^Tx - 2*x^Ty + y^Ty)\n",
        "        exponent = XX - 0.5 * X2 - 0.5 * tf.transpose(X2)\n",
        "\n",
        "        # scaling constants for each of the rows in 'X'\n",
        "        s = makeScaleMatrix(x.shape[0], x.shape[0])\n",
        "\n",
        "        # scaling factors of each of the kernel values, corresponding to the\n",
        "        # exponent values\n",
        "        S = tf.matmul(s, tf.transpose(s))\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # for each bandwidth parameter, compute the MMD value and add them all\n",
        "        for i in range(len(sigma)):\n",
        "            # kernel values for each combination of the rows in 'X'\n",
        "            kernel_val = tf.exp(1.0 / sigma[i] * exponent)\n",
        "            loss += tf.reduce_sum(S * kernel_val)\n",
        "        return tf.sqrt(loss)\n",
        "\n",
        "\n",
        "def _mmd_loss_block(x, gen_x, sigma = [2, 5, 10, 20, 40, 80]):\n",
        "        # concatenation of the generated images and images from the dataset\n",
        "        # first 'N' rows are the generated ones, next 'M' are from the data\n",
        "        X = tf.transpose(tf.concat([gen_x, x], axis=0), perm = [1, 2, 0, 3])\n",
        "\n",
        "        # dot product between all combinations of rows in 'X'\n",
        "        XX = tf.matmul(X, tf.transpose(X, perm = [0, 1, 3, 2]))\n",
        "\n",
        "        # dot product of rows with themselves\n",
        "        X2 = tf.reduce_sum(X * X, -1, keepdims=True)\n",
        "\n",
        "        # exponent entries of the RBF kernel (without the sigma) for each\n",
        "        # combination of the rows in 'X'\n",
        "        # -0.5 * (x^Tx - 2*x^Ty + y^Ty)\n",
        "        exponent = XX - 0.5 * X2 - 0.5 * tf.transpose(X2, perm = [0, 1, 3, 2])\n",
        "\n",
        "        # scaling constants for each of the rows in 'X'\n",
        "        s = makeScaleMatrix(x.shape[0], x.shape[0])\n",
        "\n",
        "        # scaling factors of each of the kernel values, corresponding to the\n",
        "        # exponent values\n",
        "        S = tf.matmul(s, tf.transpose(s))\n",
        "\n",
        "        loss = 0\n",
        "        # for each bandwidth parameter, compute the MMD value and add them all\n",
        "        for i in range(len(sigma)):\n",
        "            # kernel values for each combination of the rows in 'X'\n",
        "            kernel_val = tf.exp(1.0 / sigma[i] * exponent)\n",
        "            loss += tf.reduce_sum(S * kernel_val)\n",
        "        return tf.sqrt(loss)\n",
        "\n",
        "\n",
        "# convert mmd_loss1 into block version\n",
        "# current norm might be better with RBF kernels as in mmd_loss\n",
        "def _mmd_loss2(x, y):\n",
        "    xx = tf.matmul(x, tf.transpose(x))\n",
        "    yy = tf.matmul(y, tf.transpose(y))\n",
        "    xy = tf.matmul(x, tf.transpose(y))\n",
        "    mmd = tf.reduce_mean(xx) - 2*tf.reduce_mean(xy) + tf.reduce_mean(yy)\n",
        "    return tf.sqrt(mmd)\n",
        "\n",
        "\n",
        "def _energy_loss(y_pred1, y_pred2, y_true):\n",
        "    norm1 = tf.norm(y_pred1 - y_pred2, axis=1)\n",
        "    norm2 = tf.norm(y_pred1 - y_true, axis=1)\n",
        "    energy_score = 0.5*norm1**0.5 - norm2**0.5\n",
        "    return -tf.reduce_mean(energy_score, axis=0)\n",
        "\n",
        "\n",
        "def _rbf_kernel(x, y, scale):\n",
        "  return  tf.exp(-(x - y)**2 / (scale))\n",
        "\n",
        "\n",
        "def _energy_loss_block(y_pred1, y_pred2, y_true, power):\n",
        "    norm1 = tf.norm(y_pred1 - y_pred2, axis=3)\n",
        "    norm2 = tf.norm(y_pred1 - y_true, axis=3)\n",
        "    norm1 = tf.where(tf.equal(norm1, 0), tf.zeros_like(norm1), norm1)\n",
        "    norm2 = tf.where(tf.equal(norm2, 0), tf.zeros_like(norm2), norm2)\n",
        "    energy_score = 0.5 * norm1**power - norm2**power\n",
        "    energy_score = tf.reduce_sum(energy_score, axis=(1, 2))\n",
        "    return - tf.reduce_mean(energy_score, axis=0)\n",
        "\n",
        "\n",
        "def compute_kernel(x, y):\n",
        "    x_size = tf.shape(x)[0]\n",
        "    y_size = tf.shape(y)[0]\n",
        "    dim = tf.shape(x)[1]\n",
        "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])),\n",
        "                      tf.stack([1, y_size, 1]))\n",
        "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])),\n",
        "                      tf.stack([x_size, 1, 1]))\n",
        "    return tf.exp(- tf.reduce_mean(\n",
        "        tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
        "\n",
        "\n",
        "def compute_mmd(x, y):\n",
        "    x_kernel = compute_kernel(x, x)\n",
        "    y_kernel = compute_kernel(y, y)\n",
        "    xy_kernel = compute_kernel(x, y)\n",
        "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)\n",
        "\n",
        "\n",
        "def _energy_loss_block_kernel(y_pred1, y_pred2, y_true, sigma = [2, 5, 10, 20, 40, 80]):\n",
        "    loss = 0\n",
        "    for scale in sigma:\n",
        "      xx = _rbf_kernel(y_pred1, y_pred2, scale)\n",
        "      xy = _rbf_kernel(y_pred1, y_true, scale)\n",
        "      energy_score = 0.5 * tf.reduce_sum(xx, axis = 3) - tf.reduce_sum(xy, axis = 3)\n",
        "      energy_score = tf.reduce_sum(energy_score, axis = [1, 2])\n",
        "      loss = loss - tf.reduce_mean(energy_score, axis=0)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def quantile_loss(y_pred, y_true, alpha):\n",
        "  # note: all inputs have shape (n_batch, n_dims)\n",
        "  loss_vector = tf.maximum(\n",
        "      alpha * (y_true - y_pred),\n",
        "      (alpha - 1) * (y_true - y_pred))\n",
        "  return tf.reduce_mean(loss_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrraXkIeeOMZ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import BatchNormalization\n",
        "import random\n",
        "# define model\n",
        "class PixelCNN_MMD(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PixelCNN_MMD, self).__init__(**kwargs)\n",
        "        # create model layers\n",
        "        self.x_decoder = PixelConvLayer(\n",
        "            mask_type=\"A\", filters=64, kernel_size=3,\n",
        "            activation=\"linear\", padding=\"same\")\n",
        "        self.z_decoder = PixelConvLayer(\n",
        "            mask_type=\"B\", filters=64, kernel_size=3,\n",
        "            activation=\"linear\", padding=\"same\")\n",
        "        self.residual_blocks = []\n",
        "        for _ in range(n_residual_blocks):\n",
        "            self.residual_blocks.append(ResidualBlock(filters=128))\n",
        "\n",
        "        self.lrelu = LeakyReLU(0.1)\n",
        "\n",
        "        self.pixel_convs = []\n",
        "        self.pixel_convs.append(PixelConvLayer(\n",
        "              mask_type=\"B\",\n",
        "              filters=128,\n",
        "              kernel_size=1,\n",
        "              strides=1,\n",
        "              activation=\"linear\",\n",
        "              padding=\"valid\",\n",
        "          ))\n",
        "        self.pixel_convs.append(PixelConvLayer(\n",
        "              mask_type=\"B\",\n",
        "              filters=n_block_x_dim*n_block_y_dim,\n",
        "              kernel_size=1,\n",
        "              strides=1,\n",
        "              activation=\"sigmoid\",\n",
        "              padding=\"valid\",\n",
        "        ))\n",
        "        self.batchnorms = []\n",
        "        for i in range(5):\n",
        "          self.batchnorms.append(BatchNormalization(axis = 3))\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        self.power = 2\n",
        "\n",
        "    def call(self, input):\n",
        "        inputx = input[0]\n",
        "        inputz = input[1]\n",
        "        x_decoded = self.x_decoder(inputx)\n",
        "        x_decoded = self.lrelu(x_decoded)\n",
        "        z_decoded = self.z_decoder(inputz)\n",
        "        z_decoded = self.lrelu(z_decoded)\n",
        "        z_decoded = self.batchnorms[0](z_decoded)\n",
        "        z_decoded = tf.concat((x_decoded, z_decoded), -1)\n",
        "        for i in range(n_residual_blocks):\n",
        "          z_decoded = self.residual_blocks[i](z_decoded)\n",
        "          z_decoded = self.lrelu(z_decoded)\n",
        "          z_decoded = self.batchnorms[i+1](z_decoded)\n",
        "        z_decoded = self.pixel_convs[0](z_decoded)\n",
        "        z_decoded = self.lrelu(z_decoded)\n",
        "        z_decoded = self.batchnorms[4](z_decoded)\n",
        "        x_decoded = self.pixel_convs[1](z_decoded)\n",
        "        return x_decoded\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = 0\n",
        "            y_target = data[0]\n",
        "            labels = data[1]\n",
        "            shape = (y_target.shape[0], n_x_blocks, n_y_blocks,\n",
        "                     n_block_x_dim*n_block_y_dim)\n",
        "            z1 = tf.concat((tf.random.normal(shape=shape), labels), -1)\n",
        "            z2 = tf.concat((tf.random.normal(shape=shape), labels), -1)\n",
        "            y_pred1 = self((y_target, z1), training=True)\n",
        "            y_pred2 = self((y_target, z2), training=True)\n",
        "            loss = _energy_loss_block(y_pred1, y_pred2, y_target, 0.5)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        grads = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_cnn = PixelCNN_MMD()\n",
        "pixel_cnn.compile(optimizer=tf.keras.optimizers.Adam(1e-4))"
      ],
      "metadata": {
        "id": "NUs7ydUF3JQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_cnn.fit(x_train_rnn, y_train, epochs=1, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGlyoJEY05hB",
        "outputId": "b046be3a-c515-42e9-ec33-e1cdcd0a1e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 18s 27ms/step - loss: 29.0862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e7017b8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_cnn.summary()"
      ],
      "metadata": {
        "id": "zr_B_0T116PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdfa2c6-4d34-43df-8e65-49554deb305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"pixel_cnn_mmd_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pixel_conv_layer_7 (PixelCo  multiple                 9280      \n",
            " nvLayer)                                                        \n",
            "                                                                 \n",
            " pixel_conv_layer_8 (PixelCo  multiple                 15040     \n",
            " nvLayer)                                                        \n",
            "                                                                 \n",
            " residual_block_3 (ResidualB  multiple                 180608    \n",
            " lock)                                                           \n",
            "                                                                 \n",
            " residual_block_4 (ResidualB  multiple                 180608    \n",
            " lock)                                                           \n",
            "                                                                 \n",
            " residual_block_5 (ResidualB  multiple                 180608    \n",
            " lock)                                                           \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   multiple                  0         \n",
            "                                                                 \n",
            " pixel_conv_layer_12 (PixelC  multiple                 16512     \n",
            " onvLayer)                                                       \n",
            "                                                                 \n",
            " pixel_conv_layer_13 (PixelC  multiple                 2064      \n",
            " onvLayer)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  multiple                 256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 587,026\n",
            "Trainable params: 585,872\n",
            "Non-trainable params: 1,154\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-na6xTkdCadR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3251f0d8-68e2-4f66-ee9a-e64322586c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_13_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_14_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "pixel_cnn.save('./pixelcnn.mdl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYyHrIWtqY8W"
      },
      "source": [
        "## Demonstration\n",
        "\n",
        "The PixelCNN cannot generate the full image at once. Instead, it must generate each pixel in\n",
        "order, append the last generated pixel to the current image, and feed the image back into the\n",
        "model to repeat the process.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/pixel-cnn-mnist) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/pixelcnn-mnist-image-generation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfyA6wp4fSZI"
      },
      "outputs": [],
      "source": [
        "temp = keras.models.load_model('./pixelcnn.mdl')\n",
        "pixel_cnn = PixelCNN_MMD()\n",
        "pixel_cnn.set_weights(temp.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US7AhRVEOWX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d295e4a-322d-4c60-bbd5-6c007d9d54a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5940, 7, 7, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 1/7 [00:07<00:42,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 2/7 [00:14<00:35,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 6ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 0s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 3/7 [00:21<00:27,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 0s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 4/7 [00:25<00:17,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 7ms/step\n",
            "186/186 [==============================] - 1s 5ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 5/7 [00:33<00:13,  6.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 0s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 6/7 [00:38<00:06,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 3ms/step\n",
            "186/186 [==============================] - 1s 7ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n",
            "186/186 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:47<00:00,  6.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.14532995223999\n"
          ]
        }
      ],
      "source": [
        "# Create an empty array of pixels.\n",
        "batch = 297 * 20\n",
        "given = 0\n",
        "pixels = np.zeros(shape=(batch,) + input_shape)\n",
        "batch, rows, cols, channels = pixels.shape\n",
        "alpha = tf.random.normal(shape=pixels.shape) # (n_batch, n_dims)\n",
        "\n",
        "conditional = np.zeros((pixels.shape[0], pixels.shape[1], pixels.shape[2], 10))\n",
        "for i in range(0, conditional.shape[0]):\n",
        "  conditional[i, :, :, random.randint(0, 9)] = 1.\n",
        "conditional.astype(np.float32)\n",
        "alpha = tf.concat((alpha, conditional), axis = -1)\n",
        "print(alpha.shape)\n",
        "\n",
        "start_time = time.time()\n",
        "# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n",
        "for row in tqdm(range(given, rows)):\n",
        "    for col in range(cols):\n",
        "          # Feed the whole array and retrieving the pixel value probabilities for the next\n",
        "          # pixel.\n",
        "          value = pixel_cnn.predict((pixels, alpha))[:, row, col, :]\n",
        "          # Use the probabilities to pick pixel values and append the values to the image\n",
        "          # frame.\n",
        "          pixels[:, row, col, :] = value\n",
        "print(time.time()-start_time)\n",
        "\n",
        "pixels2 = np.zeros(shape=(batch,n_dims, n_dims))\n",
        "for b in range(batch):\n",
        "  for i in range(n_x_blocks):\n",
        "      for j in range(n_y_blocks):\n",
        "          digit = pixels[b,i, j,:].reshape([n_block_x_dim, n_block_y_dim])\n",
        "          pixels2[b, i * n_block_x_dim: (i + 1) * n_block_x_dim,\n",
        "                          j * n_block_y_dim: (j + 1) * n_block_y_dim] = digit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 100\n",
        "testing_x = np.repeat(x_test_rnn[0: 1], 100, 0)\n",
        "testing_y = np.repeat(y_test[0: 1], 100, 0)\n",
        "# testing_x = x_test_rnn[0:batch]\n",
        "# testing_y = y_test[0:batch]\n",
        "alpha = tf.random.normal(shape=testing_x.shape)\n",
        "alpha = tf.concat((alpha, testing_y), axis = -1)\n",
        "pixels = pixel_cnn.predict((testing_x, alpha))\n",
        "pixels2 = np.zeros(shape=(batch,n_dims, n_dims))\n",
        "for b in range(batch):\n",
        "  for i in range(n_x_blocks):\n",
        "      for j in range(n_y_blocks):\n",
        "          digit = pixels[b,i, j,:].reshape([n_block_x_dim, n_block_y_dim])\n",
        "          pixels2[b, i * n_block_x_dim: (i + 1) * n_block_x_dim,\n",
        "                          j * n_block_y_dim: (j + 1) * n_block_y_dim] = digit"
      ],
      "metadata": {
        "id": "0cSYj2KkS9qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9089cf5-452a-4a6e-962a-54b03179183b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 77ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5mmudPUDuCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "de27e5c4-28f7-43f1-ed97-04b6a3f79d6b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3add1a59032c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixels2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         figure[i * digit_size: (i + 1) * digit_size,\n\u001b[1;32m     12\u001b[0m                j * digit_size: (j + 1) * digit_size] = digit\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (8,8)"
          ]
        }
      ],
      "source": [
        "# display a 2D manifold of the digits\n",
        "n = 10 # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        digit = pixels2[i*n + j].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()\n",
        "#keep training and checking, can probably still keep training a li\n",
        "#plot samples incrementally - see how the image quality improves\n",
        "#get much better looking samples by doing some dimensionality reduction first? (autoencoder first, or PCA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDxE5sE8Dz_c"
      },
      "outputs": [],
      "source": [
        "np.save(\"pixelcnn-digits-1-revised.npy\", pixels2.reshape(10000, 64))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}